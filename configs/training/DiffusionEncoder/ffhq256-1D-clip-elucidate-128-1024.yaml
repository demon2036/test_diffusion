{
  "train": {
      image_size: 128,
      batch_size: 64,
      file_path: '/root/data/FFHQ256',
      seed: 43,
      total_steps: 500000,
      sample_steps: 10000,
      save_path: 'result/Diffusion',
      model_path: 'check_points/DiffAE'
  },
  "State": {
    target: modules.state_utils.EMATrainState,
    Input_Shape: [[1,128,128,3],[1,],[1,128,128,3]],
    Model: {
      target: modules.models.diffEncoder.DiffEncoder,
      params: {
        dim: 64,
        out_channels: 3,
        num_res_blocks: 2,
        dim_mults: [ 1, 1, 2, 2, 4, 4 ],
        encoder_type: '1D',
        latent_type: 'clip',
        encoder_configs: {
          dims: [ 64,128,256,256,512,512,512 ],
          dtype: 'bfloat16',
          latent: 1024,
        }
      }
    },
    Optimizer: {
        target: optax.adamw,
        params: {
          learning_rate: 2.0e-4,
          b1: 0.9,
          b2: 0.99
        }
    },
  },
  "Gaussian": {
    target: modules.score.elucidateAutoEncoder.ElucidateAutoEncoder,
    params: {
      sample_shape: [ 128,128,3 ],
      loss: 'l2',
    },
  }
}